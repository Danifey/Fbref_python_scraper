Your SE software project can be used to answer the following questions.

Add a DSA.md file to your code attempting the following questions based on how far you got:

    What dataset do you analyze? Are there multiple tables? For each table, answer what are the rows and what are the columns
    we analyzed the FBref.com player's seasons for the past 7 years within the big 5 euro leagues due to time constraints the league url has to be manually entered. There are multiple tables, our main program league table generated by Chad's Navigation, and two error tables: my network error fetch table and Justin's soup error table. 
    the main player seasons tables has 13 players stat columns associated with each player. each row is a new player season with player seasons grouped by when they first appeared on team not alphebetical order.
    if we had more people or time we would implament a ux that includes the ability to sort csvs once sorted but as are the CSVs can easilly be put in jupyter notebook and data science prerformed on them. 
    What questions is your software meant to answer on your dataset?
    our software is meant to grab data from a website and put it on a CSV, my error logger is meant to answer when fbref page site errors occured and for what url. like the benchwarmer of gebralter our edge case of edgecases it was common to have some missing 
    player data, sometimes even whole player seasons, the benchwarmer of gebralter played for 1 minute total, we had to find this information on a different site beceause fbref deemed them so unimportant as to list them but not even give them a page link, 
    they were the only one to do this.
    What algorithms and data structures did you use?
    our group used lots, for fetchwithtimer i used a timing algorithm that maintains a minimum interval between requests and overlaps wait time with compute and load time. i also used a requests algorithm to get the content of a page as a text object. 
    I also used a database error logger where the url and response of every request would also be recorded alongside time so we could see where network errors were occuring. I used a stack data structure beceause we are scrapign the existing database the only
    two CRUD operations we use are read and Create 
    What is their time and space complexity using big oh notation?
    there is a rate limiter on the site of 2 secconds this bottle neck far outweighs any compute time and my function overlaps this weight time with compute and load so to minimize runtime. so our run time t(n)=(2*N)
    How can someone test your code? For example, what are some example inputs and the corresponding output you expect.
        Consider what the command-line interface would be, or API requests and responses if you have a website. there is currently no api or command line, just run Navigation.py and it will scann a league, change the league url variable for a different league.
        if we had more time we would obviously make this part of a ui where the user could enter league url for scanning or input player name to search the csv our program creates  for player information and return the player stats as a radial bar chart. we could
        also apply a K means clustering algorithm to the data, i think it would be interesting to see what petterns emerge. 
    What challenges did you encounter and how did you solve them?
    we were the smallest group in Software engineering class, if we had ten people like the website team we could have split into front end and back end to do some data visualization and UX for our program. Patrick and I were the only ones with python experience so we spen a lot of time helping others with basic python functionality. i cant tell you how  many times i heard "you can just do that in python?!"
    one week before our project started Fbref added a bot detection to its site, i implamented bot compliance. the site we used for server hosting is so small that the CEO does tech support, cocal had issues with uploads but our ticket was resolved. 
    we had to learn how to troubleshoot network errors beceause of the sheer volume of pages being accessed I created the error logging function which justin copied for his soup error checker, in retros he said the project would not have been completed
    the error loging. beceause the small scale error logging techniques we are used to using just dont work at scale. 
    What programming languages, frameworks, or technologies did you use?
    we used python3 language, beautiful soup web scraping library.
    Who are your teammates, if any?
    Justin, Chad, Patrick, Quyhn, and Nicole.
If you worked with teammates, each person should answer these questions individually
